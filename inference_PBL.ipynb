{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takahira/anaconda3/envs/seg/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from seggpt_engine import inference_image, inference_video, inference_video_by_image\n",
    "import models_seggpt\n",
    "from PIL import Image\n",
    "from IPython.display import Image\n",
    "\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# モデルをロード\n",
    "def prepare_model(chkpt_dir, arch='seggpt_vit_large_patch16_input896x448', seg_type='instance'):\n",
    "    # build model\n",
    "    model = getattr(models_seggpt, arch)()\n",
    "    model.seg_type = seg_type\n",
    "    # load model\n",
    "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
    "    msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = 'seggpt_vit_large_patch16_input896x448'\n",
    "checkpoint = 'seggpt_vit_large.pth'\n",
    "\n",
    "\n",
    "model = prepare_model(checkpoint, model).to(device)\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一枚の画像をセグメンテーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "処理の流れイメージ画像をはる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/20240613_063932/output_penguin_input.png\n"
     ]
    }
   ],
   "source": [
    "input_image_path = 'images/inputs/penguin_input.jpeg'\n",
    "prompt_image_path = 'images/inputs/penguin_target.jpeg'\n",
    "prompt_target_path = 'images/masks/penguin.png'\n",
    "out_dir = 'output/'\n",
    "\n",
    "now = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# 新しいディレクトリのパス\n",
    "new_out_dir = os.path.join(out_dir, now)\n",
    "\n",
    "if not os.path.exists(new_out_dir):\n",
    "    os.makedirs(new_out_dir)\n",
    "\n",
    "img_name = os.path.basename(input_image_path)\n",
    "out_path = os.path.join(new_out_dir, \"output_\" + '.'.join(img_name.split('.')[:-1]) + '.png')\n",
    "print(out_path)\n",
    "\n",
    "inference_image(model, device, input_image_path, prompt_image_path, prompt_target_path, out_path)\n",
    "Image(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 動画をセグメンテーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プロンプト画像を用いてセグメンテーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "処理の流れイメージ画像をはる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/20240613_084539/output_duck.mp4\n"
     ]
    }
   ],
   "source": [
    "input_video_path = 'images/inputs/duck.mp4'\n",
    "prompt_image = Image.open('images/inputs/duck.jpeg').convert(\"RGB\")\n",
    "prompt_target = Image.open('images/masks/duck.png').convert(\"RGB\")\n",
    "out_dir = 'output/'\n",
    "\n",
    "num_frames = 1 # number of prompt frames in video\n",
    "\n",
    "now = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "new_out_dir = os.path.join(out_dir, now)\n",
    "\n",
    "if not os.path.exists(new_out_dir):\n",
    "    os.makedirs(new_out_dir)\n",
    "\n",
    "img_name = os.path.basename(input_video_path)\n",
    "out_path = os.path.join(new_out_dir, \"output_\" + '.'.join(img_name.split('.')[:-1]) + '.mp4')\n",
    "print(out_path)\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(out_path, fourcc, fps, (width, height), True)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    input_img = Image.fromarray(frame[:, :, ::-1]).convert('RGB')\n",
    "    mask, output = inference_video_by_image(model, device, input_img, [prompt_image], [prompt_target], out_path)\n",
    "    video_writer.write(np.ascontiguousarray(output.astype(np.uint8)[:, :, ::-1]))\n",
    "\n",
    "video_writer.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "動画の初めのフレームをプロンプトとしてセグメンテーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "処理の流れイメージ画像をはる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/20240613_082440/output_knife.mp4\n"
     ]
    }
   ],
   "source": [
    "# 画像をもとに動画セグメンテーションする場合\n",
    "\n",
    "input_video_path = 'images/inputs/knife.mp4'\n",
    "prompt_image = Image.open('images/inputs/knife.png').convert(\"RGB\")\n",
    "prompt_target = Image.open('images/masks/knife.png').convert(\"RGB\")\n",
    "out_dir = 'output/'\n",
    "\n",
    "\n",
    "now = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "new_out_dir = os.path.join(out_dir, now)\n",
    "\n",
    "if not os.path.exists(new_out_dir):\n",
    "    os.makedirs(new_out_dir)\n",
    "\n",
    "img_name = os.path.basename(input_video_path)\n",
    "out_path = os.path.join(new_out_dir, \"output_\" + '.'.join(img_name.split('.')[:-1]) + '.mp4')\n",
    "print(out_path)\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(out_path, fourcc, fps, (width, height), True)\n",
    "\n",
    "first_flg = True\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    input_img = Image.fromarray(frame[:, :, ::-1]).convert('RGB')\n",
    "    if first_flg:\n",
    "        mask, output = inference_video_by_image(model, device, input_img, [prompt_image], [prompt_target], out_path)\n",
    "        first_flg = False\n",
    "    else:\n",
    "        mask, output = inference_video_by_image(model, device, input_img, [prompt_image, pre_image], [prompt_target, mask], out_path)\n",
    "    pre_image = input_img\n",
    "    video_writer.write(np.ascontiguousarray(output.astype(np.uint8)[:, :, ::-1]))\n",
    "\n",
    "video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カラーマスクの使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/20240613_071309/output_dog_min.mp4\n"
     ]
    }
   ],
   "source": [
    "input_video_path = 'images/inputs/dogs.mp4'\n",
    "prompt_image = Image.open('images/inputs/dogs.png').convert(\"RGB\")\n",
    "prompt_target = Image.open('images/masks/dogs.png').convert(\"RGB\")\n",
    "out_dir = 'output/'\n",
    "\n",
    "\n",
    "now = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "new_out_dir = os.path.join(out_dir, now)\n",
    "\n",
    "if not os.path.exists(new_out_dir):\n",
    "    os.makedirs(new_out_dir)\n",
    "\n",
    "img_name = os.path.basename(input_video_path)\n",
    "out_path = os.path.join(new_out_dir, \"output_\" + '.'.join(img_name.split('.')[:-1]) + '.mp4')\n",
    "print(out_path)\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(out_path, fourcc, fps, (width, height), True)\n",
    "\n",
    "first_flg = True\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    input_img = Image.fromarray(frame[:, :, ::-1]).convert('RGB')\n",
    "    if first_flg:\n",
    "        mask, output = inference_video_by_image(model, device, input_img, [prompt_image], [prompt_target], out_path)\n",
    "        first_flg = False\n",
    "    else:\n",
    "        mask, output = inference_video_by_image(model, device, input_img, [prompt_image, pre_image], [prompt_target, mask], out_path)\n",
    "    pre_image = input_img\n",
    "    video_writer.write(np.ascontiguousarray(output.astype(np.uint8)[:, :, ::-1]))\n",
    "\n",
    "video_writer.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output/commandline/dog_result.mp4.\n",
      "Moviepy - Writing video output/commandline/dog_result.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output/commandline/dog_result.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "def create_video_from_images(image_folder, output_video_path, fps=24):\n",
    "    # 画像フォルダ内のファイル名を取得してソート\n",
    "    images = sorted([os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(\".png\") or img.endswith(\".jpg\")])\n",
    "\n",
    "    # 画像から動画クリップを作成\n",
    "    clip = ImageSequenceClip(images, fps=fps)\n",
    "    \n",
    "    # 動画を出力\n",
    "    clip.write_videofile(output_video_path, codec=\"libx264\")\n",
    "\n",
    "image_folder = 'output/commandline/result'\n",
    "output_video_path = 'output/commandline/dog_result.mp4'\n",
    "create_video_from_images(image_folder, output_video_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
